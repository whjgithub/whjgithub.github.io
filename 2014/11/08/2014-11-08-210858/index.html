<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>如何爬取豆瓣妹子上的照片 | WHJ&#39;s blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="豆瓣妹子是一个收集豆瓣美女的第三方网站，主要收集来自豆瓣羞涩组，害羞组，长腿组等兴趣爱好小组的用户自行上传的照片，大家在这边可以收藏自己喜欢的豆瓣美女。那么我们怎么很快的下载这些妹子的照片到自己的电脑上来收藏呢？好吧，我承认我写了个可以很快下载这些照片的爬虫程序，有多快？试过你就知道。　　虽然这个想法是我看来的，但是代码都是我自己写的。好的话不多说，下面开始啦。">
<meta property="og:type" content="article">
<meta property="og:title" content="如何爬取豆瓣妹子上的照片">
<meta property="og:url" content="http://yoursite.com/2014/11/08/2014-11-08-210858/">
<meta property="og:site_name" content="WHJ's blog">
<meta property="og:description" content="豆瓣妹子是一个收集豆瓣美女的第三方网站，主要收集来自豆瓣羞涩组，害羞组，长腿组等兴趣爱好小组的用户自行上传的照片，大家在这边可以收藏自己喜欢的豆瓣美女。那么我们怎么很快的下载这些妹子的照片到自己的电脑上来收藏呢？好吧，我承认我写了个可以很快下载这些照片的爬虫程序，有多快？试过你就知道。　　虽然这个想法是我看来的，但是代码都是我自己写的。好的话不多说，下面开始啦。">
<meta property="og:image" content="http://whj-img.qiniudn.com/doubanmeizi2.jpg">
<meta property="og:image" content="http://whj-img.qiniudn.com/doubanmeizi1.jpg">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="如何爬取豆瓣妹子上的照片">
<meta name="twitter:description" content="豆瓣妹子是一个收集豆瓣美女的第三方网站，主要收集来自豆瓣羞涩组，害羞组，长腿组等兴趣爱好小组的用户自行上传的照片，大家在这边可以收藏自己喜欢的豆瓣美女。那么我们怎么很快的下载这些妹子的照片到自己的电脑上来收藏呢？好吧，我承认我写了个可以很快下载这些照片的爬虫程序，有多快？试过你就知道。　　虽然这个想法是我看来的，但是代码都是我自己写的。好的话不多说，下面开始啦。">

  
    <link rel="alternative" href="/atom.xml" title="WHJ&#39;s blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" href="/css/style.css" type="text/css">

  <script src="http://libs.baidu.com/jquery/1.9.0/jquery.js"></script>
</head>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<div class="profilepic">
			<img src="http://whj-img.qiniudn.com/2014-11-03_145609.png">
		</div>

		<hgroup>
		  <h1 class="header-author"><a href="/">WHJ</a></h1>
		</hgroup>

		
		<p class="header-subtitle">WHJ&#39;s Heroic Joker</p>
		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						<div class="icon-wrap icon-link hide" data-idx="2">
							<div class="loopback_l"></div>
							<div class="loopback_r"></div>
						</div>
						
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>菜单</li>
						<li>标签</li>
						
						<li>友情链接</li>
						
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/archives">所有文章</a></li>
				        
							<li><a href="/about">关于作者</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="github" target="_blank" href="https://github.com/whjgithub" title="github">github</a>
					        
								<a class="rss" target="_blank" href="/atom.xml" title="rss">rss</a>
					        
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud">
						<a href="/tags/javascript/" style="font-size: 13.33px;">javascript</a><a href="/tags/python/" style="font-size: 13.33px;">python</a><a href="/tags/原创/" style="font-size: 16.67px;">原创</a><a href="/tags/数据结构/" style="font-size: 13.33px;">数据结构</a><a href="/tags/笔记/" style="font-size: 20.00px;">笔记</a><a href="/tags/随笔/" style="font-size: 10.00px;">随笔</a>
					</div>
				</section>
				
				
				
				<section class="switch-part switch-part3">
					
			          <a target="_blank" class="main-nav-link switch-friends-link" href="http://chenpengdsp.com">CP师兄的博客</a>
			        
				</section>
				

				
			</div>
		</div>
	</header>				
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay"></div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img src="http://whj-img.qiniudn.com/2014-11-03_145609.png">
			</div>

			<hgroup>
			  <h1 class="header-author"><a href="/">WHJ</a></h1>
			</hgroup>
			
			<p class="header-subtitle">WHJ&#39;s Heroic Joker</p>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/archives">所有文章</a></li>
		        
					<li><a href="/about">关于作者</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/whjgithub" title="github">github</a>
			        
						<a class="rss" target="_blank" href="/atom.xml" title="rss">rss</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>
      <article id="post-2014-11-08-210858" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2014/11/08/2014-11-08-210858/" class="article-date">
  	<time datetime="2014-11-08T13:08:58.000Z" itemprop="datePublished">Nov 8 2014</time>
</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/">python</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/原创/">原创</a></li></ul>

    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      如何爬取豆瓣妹子上的照片
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>　　<a href="http://www.dbmeizi.com" title="豆瓣妹子的超链接" target="_blank" rel="external">豆瓣妹子</a>是一个收集豆瓣美女的第三方网站，主要收集来自豆瓣羞涩组，害羞组，长腿组等兴趣爱好小组的用户自行上传的照片，大家在这边可以收藏自己喜欢的豆瓣美女。那么我们怎么很快的下载这些妹子的照片到自己的电脑上来收藏呢？好吧，我承认我写了个可以很快下载这些照片的爬虫程序，有多快？试过你就知道。<br>　　虽然这个想法是我看来的，但是代码都是我自己写的。好的话不多说，下面开始啦。<br><a id="more"></a></p>
<hr>
<p>　　其首页的布局如下图。有这么多栏目，我们就以白色区域的栏目来讲解吧。<br>　　　　　　　<img src="http://whj-img.qiniudn.com/doubanmeizi1.jpg" alt="贴图1"><br>　　首先主页的网址是：<a href="http://www.dbmeizi.com" target="_blank" rel="external">http://www.dbmeizi.com</a>，“所有”是：<a href="http://www.dbmeizi.com/category/10" target="_blank" rel="external">http://www.dbmeizi.com/category/10</a>，“性感”是：<a href="http://www.dbmeizi.com/category/1" target="_blank" rel="external">http://www.dbmeizi.com/category/1</a>，等等就不一个个说了，自己打开看下，应该都是主页后面加上一定的代码。那么我们就可以写出一定的代码来取得正确的url：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">info = <span class="string">u'''</span></div><div class="line">-------------------------</div><div class="line">1.所有</div><div class="line">2.性感</div><div class="line">3.有沟</div><div class="line">4.美腿</div><div class="line">5.小清新</div><div class="line">6.文艺</div><div class="line">7.美臀</div><div class="line">请输入数字选择要下载的类别：</div><div class="line">--------------------------</div><div class="line">'''</div><div class="line">print(info)</div><div class="line">num = raw_input()  <span class="comment">#获取下载选项</span></div><div class="line"></div><div class="line">choices = {</div><div class="line">    <span class="string">'1'</span>:<span class="string">r'10'</span>,</div><div class="line">    <span class="string">'2'</span>:<span class="string">r'1'</span>,</div><div class="line">    <span class="string">'3'</span>:<span class="string">r'2'</span>,</div><div class="line">    <span class="string">'4'</span>:<span class="string">r'3'</span>,</div><div class="line">    <span class="string">'5'</span>:<span class="string">r'11'</span>,</div><div class="line">    <span class="string">'6'</span>:<span class="string">r'12'</span>,</div><div class="line">    <span class="string">'7'</span>:<span class="string">r'14'</span></div><div class="line">    }</div><div class="line">choice = choices[num]</div><div class="line">base_url = <span class="string">r'http://www.dbmeizi.com/category/'</span></div><div class="line">choice_url = base_url + choice  <span class="comment">#要下载的页面的首页url</span></div></pre></td></tr></table></figure>

<p><br><br>　　我们再到开每个栏目翻页看看，就会发现同一类别不同页数之间的差别。第一页是：<a href="http://www.dbmeizi.com/category/1?p=0" target="_blank" rel="external">http://www.dbmeizi.com/category/1?p=0</a>，第二页是：<a href="http://www.dbmeizi.com/category/1?p=1" target="_blank" rel="external">http://www.dbmeizi.com/category/1?p=1</a>，细心的同学应该已经发现规律了。好的，那我们就开始写代码吧：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">print(<span class="string">u'请输入起始页数：'</span>)</div><div class="line">startpage = input() - <span class="number">1</span></div><div class="line">print(<span class="string">u'请输入结束页数：'</span>)</div><div class="line">endpage = input() - <span class="number">1</span></div><div class="line">page_index = <span class="string">r'?p='</span></div><div class="line">url_pages = []  <span class="comment">#储存所有要下载的url</span></div><div class="line"><span class="comment">#拼接url的各个部分</span></div><div class="line"><span class="keyword">for</span> index <span class="keyword">in</span> range(startpage, endpage + <span class="number">1</span>):</div><div class="line">    url_pages.append(choice_url + page_index + str(index))</div></pre></td></tr></table></figure>

<p>　　其中的<code>input() == eval(raw_input())</code>，在这里我们可以直接使我们取得的变量为整形。我们分了几个部分把每个页面的url给拼接了出来，注意最后拼接的时候必须全都是字符串才行。<br><br><br>　　在下载之前我们还有2个问题要解决：</p>
<blockquote>
<ul>
<li>第一：下载的图片放哪里？</li>
<li>第二：图片的链接是什么？</li>
</ul>
</blockquote>
<p> 　　第一个问题的解决方法显然就是要创建或选择一个文件夹，那我们就写个简单的代码吧：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> os  <span class="comment">#引入os模块</span></div><div class="line">print(<span class="string">u'请输入要保存图片的绝对路径：'</span>)  </div><div class="line">dir_path = raw_input()  <span class="comment">#保存路径名</span></div><div class="line">print(<span class="string">u'请输入要保存图片的文件夹名称：'</span>)  </div><div class="line">dir_title = raw_input()  <span class="comment">#保存文件夹名</span></div><div class="line">new_path = os.path.join(dir_path, dir_title)  <span class="comment">#拼接出最终的路径</span></div><div class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(new_path):  <span class="comment">#如果不存在就创建文件夹</span></div><div class="line">    os.makedirs(new_path)</div><div class="line">    print(<span class="string">u'将把图片保存在：%s'</span> % new_path)</div></pre></td></tr></table></figure>

<p> 　　第二个问题是要得到下载的链接。写过爬虫的肯定知道这一步是必须用<a href="http://www.cnblogs.com/huxi/archive/2010/07/04/1771073.html" target="_blank" rel="external"><strong>正则表达式</strong></a>的，没错，那我们就一步步来看。上面我们已经取得了要下载的各个页面的url，打开一个，在一张图片上右击“审查元素”，我们可以看到下面图片显示的信息：<br> <img src="http://whj-img.qiniudn.com/doubanmeizi2.jpg" alt="贴图2"><br>　　我们看到阴影处就是图片的<code>html</code>代码，学过<code>html</code>的都知道图片的链接就在<code>src</code>后面双引号里，没学过看到<code>.jpg</code>也明白了吧。好了有了这一串代码我们就要开始解析并匹配了，之后取到各个链接之后我们直接下载保存在我们建好的文件夹里就行了。代码如下：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> urllib2,re,urllib  <span class="comment">#引入需要的模块</span></div><div class="line"><span class="comment">#开始下载该页面所有的图片</span></div><div class="line">j = startpage  <span class="comment">#用来给图片编号</span></div><div class="line"><span class="keyword">for</span> page <span class="keyword">in</span> url_pages:  <span class="comment">#循环每个要下载的页面</span></div><div class="line">    myUrl = page  <span class="comment">#取出一个url</span></div><div class="line">    content = urllib2.urlopen(myUrl).read().decode(<span class="string">'utf-8'</span>)  <span class="comment">#获取url的html代码</span></div><div class="line">    pattern = re.compile(<span class="string">r'&lt;img.*?class=".*?_min".*?src="(.*?)".*?alt=.*?&gt;'</span>\</div><div class="line">                         ,re.S)  <span class="comment">#正则表达式对象</span></div><div class="line">    allurl = re.findall(pattern, content)  <span class="comment">#找到并返回所有符合对象的值，即图片链接</span></div><div class="line"></div><div class="line">    i = <span class="number">0</span>  <span class="comment">#编号用</span></div><div class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> allurl: </div><div class="line">        location = <span class="string">r'%s\%s_%s.jpg'</span> % (new_path, j, i)  <span class="comment">#图片存储路径</span></div><div class="line">        urllib.urlretrieve(item, location)  <span class="comment">#下载图片到指定位置</span></div><div class="line">        i += <span class="number">1</span></div><div class="line">    j += <span class="number">1</span></div></pre></td></tr></table></figure>

<p>　　这里需要引入<code>urllib</code>，<code>rullib</code>和<code>re</code>模块，分别用于打开链接和正则匹配。<code>urllib2.urlopen(myUrl)</code>打开url作为一个对象，然后<code>.read()</code>是读取内容，<code>.decode(&#39;utf-8&#39;)</code>是解码为<code>unicoude</code>（自身编码是utf-8）。<br>。完成这段我们就搞定了所有的代码了。<br><br><br>最后整理一下代码：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*- coding: utf-8 -*-</span></div><div class="line"><span class="keyword">import</span> os </div><div class="line"><span class="keyword">import</span> urllib2,urllib  </div><div class="line"><span class="keyword">import</span> re</div><div class="line"></div><div class="line">info = <span class="string">u'''</span></div><div class="line">-------------------------</div><div class="line">1.所有</div><div class="line">2.性感</div><div class="line">3.有沟</div><div class="line">4.美腿</div><div class="line">5.小清新</div><div class="line">6.文艺</div><div class="line">7.美臀</div><div class="line">请输入数字选择要下载的类别：</div><div class="line">--------------------------</div><div class="line">'''</div><div class="line">print(info)</div><div class="line">num = raw_input()  <span class="comment">#获取下载选项</span></div><div class="line"></div><div class="line">choices = {</div><div class="line">    <span class="string">'1'</span>:<span class="string">r'10'</span>,</div><div class="line">    <span class="string">'2'</span>:<span class="string">r'1'</span>,</div><div class="line">    <span class="string">'3'</span>:<span class="string">r'2'</span>,</div><div class="line">    <span class="string">'4'</span>:<span class="string">r'3'</span>,</div><div class="line">    <span class="string">'5'</span>:<span class="string">r'11'</span>,</div><div class="line">    <span class="string">'6'</span>:<span class="string">r'12'</span>,</div><div class="line">    <span class="string">'7'</span>:<span class="string">r'14'</span></div><div class="line">    }</div><div class="line">choice = choices[num]</div><div class="line">base_url = <span class="string">r'http://www.dbmeizi.com/category/'</span></div><div class="line">choice_url = base_url + choice  <span class="comment">#要下载的页面的首页url</span></div><div class="line"></div><div class="line">print(<span class="string">u'请输入起始页数：'</span>)</div><div class="line">startpage = input() - <span class="number">1</span></div><div class="line">print(<span class="string">u'请输入结束页数：'</span>)</div><div class="line">endpage = input() - <span class="number">1</span></div><div class="line">page_index = <span class="string">r'?p='</span></div><div class="line">url_pages = []  <span class="comment">#储存所有要下载的url</span></div><div class="line"><span class="comment">#拼接url的各个部分</span></div><div class="line"><span class="keyword">for</span> index <span class="keyword">in</span> range(startpage, endpage + <span class="number">1</span>):</div><div class="line">    url_pages.append(choice_url + page_index + str(index))</div><div class="line"></div><div class="line">print(<span class="string">u'请输入要保存图片的绝对路径：'</span>)  </div><div class="line">dir_path = raw_input()  <span class="comment">#保存路径名</span></div><div class="line">print(<span class="string">u'请输入要保存图片的文件夹名称：'</span>)  </div><div class="line">dir_title = raw_input()  <span class="comment">#保存文件夹名</span></div><div class="line">new_path = os.path.join(dir_path, dir_title)  <span class="comment">#拼接出最终的路径</span></div><div class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(new_path):  <span class="comment">#如果不存在就创建文件夹</span></div><div class="line">    os.makedirs(new_path)</div><div class="line">    print(<span class="string">u'将把图片保存在：%s'</span> % new_path)</div><div class="line"></div><div class="line">j = startpage  <span class="comment">#用来给图片编号</span></div><div class="line"><span class="keyword">for</span> page <span class="keyword">in</span> url_pages:  <span class="comment">#循环每个要下载的页面</span></div><div class="line">    myUrl = page  <span class="comment">#取出一个url</span></div><div class="line">    content = urllib2.urlopen(myUrl).read().decode(<span class="string">'utf-8'</span>)  <span class="comment">#获取url的html代码</span></div><div class="line">    pattern = re.compile(<span class="string">r'&lt;img.*?class=".*?_min".*?src="(.*?)".*?alt=.*?&gt;'</span>\</div><div class="line">                         ,re.S)  <span class="comment">#正则表达式对象</span></div><div class="line">    allurl = re.findall(pattern, content)  <span class="comment">#找到并返回所有符合对象的值，即图片链接</span></div><div class="line"></div><div class="line">    i = <span class="number">0</span>  <span class="comment">#编号用</span></div><div class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> allurl: </div><div class="line">        location = <span class="string">r'%s\%s_%s.jpg'</span> % (new_path, j, i)  <span class="comment">#图片存储路径</span></div><div class="line">        urllib.urlretrieve(item, location)  <span class="comment">#下载图片到指定位置</span></div><div class="line">        i += <span class="number">1</span></div><div class="line">    j += <span class="number">1</span></div></pre></td></tr></table></figure>

<p>　　<code># -*- coding: utf-8 -*-</code>是告诉编译器本文件的编码，在IDLE中必须加上才能运行。整理好了是不是整齐多了，赶紧去试试下载的快感吧！<br>　　本程序还是有很多的可改进之处的，比如：页数输入的正确性检测、文件夹创建过程的正确性检测、下载过程的多线程化等等还有好多，以后会改进的，敬请期待！</p>
<p>版权：本文采用以下协议进行授权，<a href="http://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="external">自由转载 - 非商用 - 非衍生 - 保持署名 | Creative Commons BY-NC-ND 3.0</a>，转载请注明作者及出处。</p>

      
    </div>
    <footer class="article-footer">
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2014/11/19/2014-11-19-210225/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">&lt;</strong>
      <div class="article-nav-title">
        
          正则表达式&lt;一&gt;
        
      </div>
    </a>
  
  
    <a href="/2014/11/07/2014-11-07-101115/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">开山篇</div>
      <strong class="article-nav-caption">&gt;</strong>
    </a>
  
</nav>

  
</article>


<div class="share">
	<!-- JiaThis Button BEGIN -->
	<div class="jiathis_style">
		<span class="jiathis_txt">分享到：</span>
		<a class="jiathis_button_tsina"></a>
		<a class="jiathis_button_cqq"></a>
		<a class="jiathis_button_douban"></a>
		<a class="jiathis_button_weixin"></a>
		<a class="jiathis_button_tumblr"></a>
		<a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jtico jtico_jiathis" target="_blank"></a>
	</div>
	<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js?uid=1405949716054953" charset="utf-8"></script>
	<!-- JiaThis Button END -->
</div>



<div class="duoshuo">
	<!-- 多说评论框 start -->
	<div class="ds-thread" data-thread-key="2014-11-08-210858" data-title="如何爬取豆瓣妹子上的照片" data-url="http://yoursite.com/2014/11/08/2014-11-08-210858/"></div>
	<!-- 多说评论框 end -->
	<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
	<script type="text/javascript">
	var duoshuoQuery = {short_name:"whjgithub"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
	<!-- 多说公共JS代码 end -->
</div>




      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2015 WHJ
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
</footer>
    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">

  <script src="/fancybox/jquery.fancybox.pack.js" type="text/javascript"></script>

  <script src="/js/main.js" type="text/javascript"></script>


  </div>
</body>
</html>